{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, BackboneFinetuning, EarlyStopping\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "import timm\n",
    "import pandas as pd\n",
    "import torchaudio as ta\n",
    "\n",
    "from modules.preprocess import preprocess,prepare_cfg\n",
    "from modules.dataset import get_train_dataloader\n",
    "from modules.model import load_model\n",
    "import modules.inception_next_nano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to repo root\n",
    "cur_dir = Path().resolve()\n",
    "\n",
    "if not (cur_dir / \"notebooks\").exists():\n",
    "    os.chdir(os.path.abspath(\"../\"))\n",
    "print(f\"{Path().resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "\n",
    "Set the configuration name for the training model.\n",
    "\n",
    "#### 2021-2nd CNN Model (seresnext26ts)\n",
    "```python\n",
    "model_name = \"cnn_v1\"\n",
    "stage = \"train_bce\"\n",
    "```\n",
    "\n",
    "#### 2021-2nd CNN Model (rexnet_150)\n",
    "```python\n",
    "model_name = \"cnn_v3_rexnet\"\n",
    "stage = \"train_bce\"\n",
    "```\n",
    "\n",
    "#### Simple CNN Model (inception_next_nano)\n",
    "```python\n",
    "model_name = \"simple_cnn_v1\"\n",
    "stage = \"train_bce\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cnn_v1\"\n",
    "stage = \"train_bce\"\n",
    "\n",
    "cfg = importlib.import_module(f'configs.{model_name}').basic_cfg\n",
    "cfg = prepare_cfg(cfg,stage)\n",
    "\n",
    "pl.seed_everything(cfg.seed[stage], workers=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_train, df_valid, df_label_train, df_label_valid, transforms = preprocess(cfg, stage)\n",
    "df_train[\"version\"] = \"2023\"\n",
    "df_valid[\"version\"] = \"2023\"\n",
    "len(df_train), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.use_2024_additional_cleaned:\n",
    "    # append handlabeled data\n",
    "    df_additional = pd.read_pickle(cfg.train_2024_additional_cleaned)\n",
    "    df_additional[\"version\"] = \"2023\"\n",
    "    df_additional[\"presence_type\"]  = \"foreground\"\n",
    "\n",
    "    # repeating records\n",
    "    df_additional = pd.concat([df_additional] * cfg.num_cleaned_repeat).reset_index(drop=True)\n",
    "\n",
    "    # make one-hot label\n",
    "    add_primary_label = pd.Categorical(df_additional[\"primary_label\"], categories=cfg.bird_cols)\n",
    "    add_primary_label = pd.get_dummies(add_primary_label,  dtype=np.float64)\n",
    "    assert (add_primary_label.columns == df_label_train.columns).all()\n",
    "\n",
    "\n",
    "    df_train = pd.concat([df_train, df_additional]).reset_index(drop=True)\n",
    "    df_label_train = pd.concat([df_label_train, add_primary_label]).reset_index(drop=True)\n",
    "    # df_train.shape\n",
    "\n",
    "    # shuffle\n",
    "    perm_idx = df_train.index.to_series().sample(frac=1, random_state=0)\n",
    "    df_train = df_train.iloc[perm_idx].reset_index(drop=True)\n",
    "    df_label_train = df_label_train.iloc[perm_idx].reset_index(drop=True)\n",
    "\n",
    "    all_primary_labels = df_train[\"primary_label\"]\n",
    "    sample_weights = (\n",
    "        all_primary_labels.value_counts() / \n",
    "        all_primary_labels.value_counts().sum()\n",
    "    )  ** (cfg.class_exponent_weight)\n",
    "    sample_weights = sample_weights / sample_weights.mean()\n",
    "    df_train[\"weight\"] = sample_weights[df_train[\"primary_label\"].values].values\n",
    "\n",
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo = None\n",
    "dl_train, dl_val, ds_train, ds_val = get_train_dataloader(\n",
    "        df_train,\n",
    "        df_valid,\n",
    "        df_label_train,\n",
    "        df_label_valid,\n",
    "        cfg,\n",
    "        pseudo,\n",
    "        transforms\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = WandbLogger(project='BirdClef-2023', name=f'{model_name}_{stage}')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    #monitor='val_loss',\n",
    "    monitor=None,\n",
    "    dirpath= cfg.output_path[stage],\n",
    "    save_top_k=0,\n",
    "    save_last= True,\n",
    "    save_weights_only=True,\n",
    "    #filename= './ckpt_epoch_{epoch}_val_loss_{val_loss:.2f}',\n",
    "    #filename ='./ckpt_{epoch}_{val_loss}',\n",
    "    verbose= True,\n",
    "    every_n_epochs=1,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_to_use = [checkpoint_callback]\n",
    "model = load_model(cfg,stage)\n",
    "trainer = pl.Trainer(\n",
    "    devices=1,\n",
    "    val_check_interval=1.0,\n",
    "    deterministic=None,\n",
    "    max_epochs=cfg.epochs[stage],\n",
    "    logger=logger,\n",
    "    callbacks=callbacks_to_use,\n",
    "    precision=cfg.PRECISION, accelerator=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_dataloaders = dl_train, val_dataloaders = dl_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
