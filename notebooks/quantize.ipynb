{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Training Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, BackboneFinetuning, EarlyStopping\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob\n",
    "import timm\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import torchaudio as ta\n",
    "\n",
    "from modules.preprocess import preprocess,prepare_cfg\n",
    "from modules.dataset import get_train_dataloader\n",
    "from modules.model import load_model\n",
    "import modules.inception_next_nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# move to repo root\n",
    "cur_dir = Path().resolve()\n",
    "\n",
    "if not (cur_dir / \"notebooks\").exists():\n",
    "    os.chdir(os.path.abspath(\"../\"))\n",
    "print(f\"{Path().resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "\n",
    "Set the configuration name for the model to calibrate.\n",
    "\n",
    "#### 2021-2nd CNN Model (seresnext26ts)\n",
    "```python\n",
    "model_name = \"cnn_v1\"\n",
    "stage = \"train_bce\"\n",
    "```\n",
    "\n",
    "#### 2021-2nd CNN Model (rexnet_150)\n",
    "```python\n",
    "model_name = \"cnn_v3_rexnet\"\n",
    "stage = \"train_bce\"\n",
    "```\n",
    "\n",
    "#### Simple CNN Model (inception_next_nano)\n",
    "```python\n",
    "model_name = \"simple_cnn_v1\"\n",
    "stage = \"train_bce\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"simple_cnn_v1\"\n",
    "stage = \"train_bce\"\n",
    "\n",
    "cfg = importlib.import_module(f'configs.{model_name}').basic_cfg\n",
    "cfg = prepare_cfg(cfg, stage)\n",
    "cfg.batch_size = cfg.quant_batch_size\n",
    "infer_len = cfg.SR * cfg.infer_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(cfg.seed[stage], workers=True)\n",
    "\n",
    "df_train, df_valid, df_label_train, df_label_valid, transforms = preprocess(cfg, stage)\n",
    "df_train[\"version\"] = \"2023\"\n",
    "df_valid[\"version\"] = \"2023\"\n",
    "len(df_train), len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compose:\n",
    "    def __init__(self, transforms: list):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        for trns in self.transforms:\n",
    "            y = trns(y, sr)\n",
    "        return y\n",
    "\n",
    "\n",
    "class AudioTransform:\n",
    "    def __init__(self, always_apply=False, p=0.5):\n",
    "        self.always_apply = always_apply\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, y: np.ndarray, sr):\n",
    "        if self.always_apply:\n",
    "            return self.apply(y, sr=sr)\n",
    "        else:\n",
    "            if np.random.rand() < self.p:\n",
    "                return self.apply(y, sr=sr)\n",
    "            else:\n",
    "                return y\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class Normalize(AudioTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply, p)\n",
    "\n",
    "    def apply(self, y: np.ndarray, **params):\n",
    "        max_vol = np.abs(y).max()\n",
    "        y_vol = y * 1 / max_vol\n",
    "        return np.asfortranarray(y_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo = None\n",
    "dl_train, dl_val, ds_train, ds_val = get_train_dataloader(\n",
    "        df_train,\n",
    "        df_valid,\n",
    "        df_label_train,\n",
    "        df_label_valid,\n",
    "        cfg,\n",
    "        pseudo,\n",
    "        transforms\n",
    "    )\n",
    "\n",
    "# torch model to use melspec transform\n",
    "if model_name != \"tmt_reshape\":\n",
    "    torch_model = load_model(cfg,stage,train=False).to(\"cpu\")\n",
    "    melspec_transform = torch_model.melspec_transform\n",
    "    db_transform = torch_model.db_transform\n",
    "else:\n",
    "    wave_transform = Compose([Normalize(p=1),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nncf\n",
    "import openvino as ov\n",
    "\n",
    "# load ovn model\n",
    "model = ov.Core().read_model(cfg.quant_ovn_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare calibration dataset\n",
    "\n",
    "def transform_fn(batch):\n",
    "    x, _, _ = batch # batch ch seg len\n",
    "    # x = x[:,:,0] # batch ch len\n",
    "    x = x[:,:,:infer_len]\n",
    "\n",
    "    if model_name != \"tmt_reshape\":\n",
    "        x = melspec_transform(x)\n",
    "        x = db_transform(x)\n",
    "\n",
    "        if cfg.normal == 80:\n",
    "            x = (x + 80) / 80\n",
    "        elif cfg.normal == 255:\n",
    "            x = x / 255\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        x = x.numpy()\n",
    "    else:\n",
    "        x = wave_transform(x.numpy(), sr=cfg.SR)\n",
    "        x = x[:,0,::2]\n",
    "\n",
    "    return x\n",
    "\n",
    "calibration_dataset = nncf.Dataset(dl_train, transform_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch for gap layer's op-set version issue\n",
    "model_gap_has_AP = [n.friendly_name for n in model.get_ops() if \"/global_pool/AveragePool\" in n.friendly_name]\n",
    "if len(model_gap_has_AP) > 0 and \"/global_pool/GlobalAveragePool\" in cfg.quant_ignore_layer_names:\n",
    "    # replace target layer name: GlobalAveragePool -> AveragePool\n",
    "    cfg_gap_idx = cfg.quant_ignore_layer_names.index(\"/global_pool/GlobalAveragePool\")\n",
    "    cfg.quant_ignore_layer_names[cfg_gap_idx] = \"/global_pool/AveragePool\"\n",
    "    print(cfg.quant_ignore_layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = nncf.quantize(\n",
    "    model, calibration_dataset, subset_size=cfg.quant_subset_size,\n",
    "    ignored_scope=nncf.IgnoredScope(names=cfg.quant_ignore_layer_names),\n",
    "    fast_bias_correction=cfg.quant_fast_bias_correction ,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.output_path[\"quantization\"], exist_ok=True)\n",
    "\n",
    "save_path = os.path.join(cfg.output_path[\"quantization\"], \"quant.xml\")\n",
    "ov.save_model(quantized_model, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
